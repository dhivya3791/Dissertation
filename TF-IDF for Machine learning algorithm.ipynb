{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FULL CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choose brand based dataset to know about Machine Learning model\n",
      "choose the below options\n",
      "\n",
      " 1.adiads Brand reviews \n",
      " 2.skechers Brand reviews \n",
      " 3.crocs Brand Reviews\n",
      "Enter number of your choice : 3\n",
      "\n",
      "**************************************************************************\n",
      "To run the particular classifier model\n",
      "choose the below options\n",
      "\n",
      " 1.Random Forest classifier         \n",
      " 2.Decision Tree classifier         \n",
      " 3.SGD classifier        \n",
      " 4.Naive Bayes\n",
      "Enter number of your choice : 4\n",
      "(13039, 5000) (13039,)\n",
      "Before balancing the data\n",
      "[(0, 1115), (1, 1126), (2, 10798)]\n",
      "After balancing the data\n",
      "class 0 --> neutral\n",
      " class 1 --> negative \n",
      " class 2 --> positive\n",
      "[(0, 10795), (1, 10796), (2, 10795)]\n",
      "Pipeline(steps=[('tfidf', TfidfTransformer()),\n",
      "                ('clf', MultinomialNB(alpha=0.2))])\n",
      "cross validation: 0.6646105298712242\n",
      "train score: 0.6930463780645958\n",
      "test score: 0.7309815950920245\n",
      "********************************************\n",
      " classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0      0.312     0.171     0.221       527\n",
      "           1      0.460     0.404     0.430       342\n",
      "           2      0.807     0.901     0.851      2391\n",
      "\n",
      "    accuracy                          0.731      3260\n",
      "   macro avg      0.526     0.492     0.501      3260\n",
      "weighted avg      0.690     0.731     0.705      3260\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def load_data():\n",
    "    ## importing the necessary library \n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import datetime\n",
    "    import seaborn as sns\n",
    "    import matplotlib.pyplot as plt\n",
    "    %matplotlib notebook\n",
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "    ### reading the data as dataframe\n",
    "    df = pd.read_excel('shoes.xlsx',sheet_name=\"Sheet2\")\n",
    "\n",
    "    ### deleting the unwanted column\n",
    "    del(df[\"marketplace\"])\n",
    "    del(df[\"customer_id\"])\n",
    "    del(df[\"review_id\"])\n",
    "    del(df[\"product_parent\"])\n",
    "    del(df[\"vine\"])\n",
    "    del(df[\"review_headline\"])\n",
    "    del(df[\"total_votes\"])\n",
    "    del(df[\"product_category\"])\n",
    "\n",
    "    #### create a brand subset\n",
    "    df['product_title']=df['product_title'].apply(lambda x: x.lower())\n",
    "\n",
    "    conditions =[(df['product_title'].str.contains('adidas')),\n",
    "                (df['product_title'].str.contains('crocs')),\n",
    "                (df['product_title'].str.contains('skechers'))]\n",
    "    values=['adidas','crocs','skechers']\n",
    "    df['Brand']=np.select(conditions,values)\n",
    "\n",
    "\n",
    "    #### labeling the data using star rating\n",
    "    df[\"verified_purchase\"]=df.verified_purchase.map({'Y':1,'N':0})\n",
    "    df[\"positivity\"] = df[\"star_rating\"].apply(lambda x: 2 if x>3 else(0 if x==3 else 1))\n",
    "\n",
    "    ### #Text Cleaning\n",
    "    # 1.1 Define preprocess function\n",
    "    df[\"review_body\"] = df[\"review_body\"].astype(\"str\")\n",
    "    import string\n",
    "    import nltk\n",
    "    #nltk.download('words')\n",
    "    words = set(nltk.corpus.words.words())\n",
    "    stopwords = nltk.corpus.stopwords.words('english')\n",
    "    new_stopwords = [\"i've\",\"i'm\",'on','ie','thesefor','im']\n",
    "    stopwords.extend(new_stopwords)\n",
    "    import re\n",
    "    wn=nltk.WordNetLemmatizer()\n",
    "\n",
    "\n",
    "    def removing_punc(ele):\n",
    "        # Convert the text into lowercase\n",
    "        ele = ele.lower()\n",
    "        #punctuation\n",
    "        ele = re.sub('[%s]' % re.escape(string.punctuation), '', ele)\n",
    "        # number\n",
    "        ele = re.sub(r'[0-9]', '', ele)\n",
    "        #new line\n",
    "        ele = re.sub('\\n', '', ele)\n",
    "        #white space\n",
    "        ele= re.sub(\"^\\s+\", \"\", ele)\n",
    "        return ele\n",
    "    df[\"review_body\"]=df[\"review_body\"].apply(lambda x: removing_punc(x))\n",
    "\n",
    "\n",
    "    def tokenize(txt):\n",
    "        \"\"\"tokenize each word by using split() function\"\"\"\n",
    "        tokens=re.split('\\W+', txt)\n",
    "        return tokens\n",
    "    df['tokenized_message']=df['review_body'].apply(lambda x: tokenize(x))\n",
    "\n",
    "    def clean_word(txt_tokenized):\n",
    "        \"\"\"removed the stopword and remove the numbers and get the base word using lemmatize function\"\"\"\n",
    "        new_word = [word for word in txt_tokenized if word not in stopwords]\n",
    "        new_word = [word for word in new_word if word.isalpha()]\n",
    "        new_word = [word for word in new_word if word in words]\n",
    "        new_word = [wn.lemmatize(word) for word in new_word]\n",
    "        return \" \".join(new_word)\n",
    "    df['st_cleaned_message']=df['tokenized_message'].apply(lambda x:clean_word(x))\n",
    "    return df\n",
    "\n",
    "\n",
    "def switch_fun(choice, t):\n",
    "    ''' based on brand of shoes the corresponding function calls'''\n",
    "    \n",
    "    from sklearn.svm import SVC\n",
    "    from sklearn.naive_bayes import MultinomialNB\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "    if choice == 1 and t == 1:\n",
    "        df=load_data()\n",
    "        x1,y1=adidas(df)\n",
    "        rf = RandomForestClassifier(max_depth=10, max_features='sqrt', n_estimators=15)\n",
    "        rf_cval,rf_tra,rf_te = machine_learning_model(x1,y1,rf)\n",
    "    elif choice == 1 and t == 2:\n",
    "        df=load_data()\n",
    "        x1,y1=adidas(df)\n",
    "        dt=DecisionTreeClassifier(max_depth=20)\n",
    "        dt_cval,dt_tra,dt_te = machine_learning_model(x1,y1,dt)\n",
    "    elif choice == 1 and t == 3:\n",
    "        df=load_data()\n",
    "        x1,y1=adidas(df)\n",
    "        sgd=SGDClassifier(loss=\"log\", penalty=\"l2\")\n",
    "        sgd_cval,sgd_tra,sgd_te = machine_learning_model(x1,y1,sgd)\n",
    "    elif choice == 1 and t == 4:\n",
    "        df=load_data()\n",
    "        x1,y1=adidas(df)\n",
    "        nb=MultinomialNB(alpha=0.2)\n",
    "        nb_cval,nb_tra,nb_te = machine_learning_model(x1,y1,nb)\n",
    "            \n",
    "    elif choice == 2 and t == 1:\n",
    "        df=load_data()\n",
    "        x1,y1=skechers(df)\n",
    "        rf = RandomForestClassifier(max_depth=10, max_features='sqrt', n_estimators=15)\n",
    "        rf_cval_s,rf_tra_s,rf_te_s = machine_learning_model(x1,y1,rf)       \n",
    "    elif choice == 2 and t == 2:\n",
    "        df=load_data()\n",
    "        x1,y1=skechers(df)\n",
    "        dt=DecisionTreeClassifier(max_depth=20)\n",
    "        dt_cval_s,dt_tra_s,dt_te_s = machine_learning_model(x1,y1,dt)        \n",
    "    elif choice == 2 and t == 3:\n",
    "        df=load_data()\n",
    "        x1,y1=skechers(df)\n",
    "        sgd=SGDClassifier(loss=\"log\", penalty=\"l2\")\n",
    "        sgd_cval_s,sgd_tra_s,sgd_te_s = machine_learning_model(x1,y1,sgd)\n",
    "    elif choice == 2 and t == 4:\n",
    "        df=load_data()\n",
    "        x1,y1=skechers(df)\n",
    "        nb=MultinomialNB(alpha=0.2)\n",
    "        nb_cval_s,nb_tra_s,nb_te_s = machine_learning_model(x1,y1,nb)\n",
    "   \n",
    "    elif choice == 3 and t == 1:\n",
    "        df=load_data()\n",
    "        x1,y1=crocs(df)\n",
    "        rf = RandomForestClassifier(max_depth=10, max_features='sqrt', n_estimators=15)\n",
    "        rf_cval_c,rf_tra_c,rf_te_c = machine_learning_model(x1,y1,rf)       \n",
    "    elif choice == 3 and t == 2:\n",
    "        df=load_data()\n",
    "        x1,y1=crocs(df)\n",
    "        dt=DecisionTreeClassifier(max_depth=20)\n",
    "        dt_cval_c,dt_tra_c,dt_te_c = machine_learning_model(x1,y1,dt)                \n",
    "    elif choice == 3 and t == 3:\n",
    "        df=load_data()\n",
    "        x1,y1=crocs(df)\n",
    "        sgd=SGDClassifier(loss=\"log\", penalty=\"l2\")\n",
    "        sgd_cval_c,sgd_tra_c,sgd_te_c = machine_learning_model(x1,y1,sgd)\n",
    "    elif choice == 3 and t == 4:\n",
    "        df=load_data()\n",
    "        x1,y1=crocs(df)\n",
    "        nb=MultinomialNB(alpha=0.2)\n",
    "        nb_cval_c,nb_tra_c,nb_te_c = machine_learning_model(x1,y1,nb)    \n",
    "    \n",
    "    else: \n",
    "        unknown_action()\n",
    "    \n",
    "def unknown_action():\n",
    "    '''if the user input is wrong'''\n",
    "    print('invalid entry')\n",
    "    print('Please enter 1 or 2 or 3 for brand reviews')\n",
    "    print('Please enter 1 or 2 or 3 or 4 for machine learning model')\n",
    "    return 0\n",
    "\n",
    "\n",
    "def adidas(dataset):\n",
    "    ### extracting only the adidas shoe brand reviews from the dataset\n",
    "    adidas = dataset[dataset[\"Brand\"]==\"adidas\"].sort_values(by=[\"review_date\"], ascending=False)\n",
    "    \n",
    "    ### Removing unwanted column\n",
    "    del(adidas['product_title'])\n",
    "    del(adidas['review_body'])\n",
    "    del(adidas['Brand'])\n",
    "    del(adidas[\"review_date\"])\n",
    "    del(adidas['star_rating'])\n",
    "    del(adidas['tokenized_message'])\n",
    "    \n",
    "    from sklearn.feature_extraction.text import CountVectorizer\n",
    "    #instantiate CountVectorizer() \n",
    "    #no of feature is 7391\n",
    "    cv=CountVectorizer(max_features=6000) \n",
    "\n",
    "    # this steps generates word counts for the words \n",
    "    word_count_vector=cv.fit_transform(adidas['st_cleaned_message'])\n",
    "    x=word_count_vector.toarray()\n",
    "    y=adidas['positivity']\n",
    "    return x,y\n",
    "\n",
    "\n",
    "def skechers(dataset):\n",
    "    ### extracting only the adidas shoe brand reviews from the dataset\n",
    "    skechers = dataset[dataset[\"Brand\"]==\"skechers\"].sort_values(by=[\"review_date\"], ascending=False)\n",
    "    \n",
    "    ### Removing unwanted column\n",
    "    del(skechers['product_title'])\n",
    "    del(skechers['review_body'])\n",
    "    del(skechers['Brand'])\n",
    "    del(skechers[\"review_date\"])\n",
    "    del(skechers['star_rating'])\n",
    "    del(skechers['tokenized_message'])\n",
    "    \n",
    "    from sklearn.feature_extraction.text import CountVectorizer\n",
    "    #instantiate CountVectorizer() \n",
    "    # no of features is 6000\n",
    "    cv=CountVectorizer(max_features=5000) \n",
    "\n",
    "    # this steps generates word counts for the words \n",
    "    word_count_vector=cv.fit_transform(skechers['st_cleaned_message'])\n",
    "    x=word_count_vector.toarray()\n",
    "    y=skechers['positivity']\n",
    "    return x,y\n",
    "\n",
    "def crocs(dataset):\n",
    "    \n",
    "    ### extracting only the adidas shoe brand reviews from the dataset\n",
    "    crocs = dataset[dataset[\"Brand\"]==\"crocs\"].sort_values(by=[\"review_date\"], ascending=False)\n",
    "    \n",
    "    ### Removing unwanted column\n",
    "    del(crocs['product_title'])\n",
    "    del(crocs['review_body'])\n",
    "    del(crocs['Brand'])\n",
    "    del(crocs[\"review_date\"])\n",
    "    del(crocs['star_rating'])\n",
    "    del(crocs['tokenized_message'])\n",
    "    \n",
    "    from sklearn.feature_extraction.text import CountVectorizer\n",
    "    #instantiate CountVectorizer() \n",
    "    # no of features is 6000\n",
    "    cv=CountVectorizer(max_features=5000) \n",
    "\n",
    "    # this steps generates word counts for the words \n",
    "    word_count_vector=cv.fit_transform(crocs['st_cleaned_message'])\n",
    "    x=word_count_vector.toarray()\n",
    "    y=crocs['positivity']\n",
    "    return x,y\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "def machine_learning_model(x1,y1,mla):\n",
    "    \n",
    "    # split the dataset as train and test for evalution\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x1, y1, test_size=0.20, random_state = 42)\n",
    "    print(x_train.shape,y_train.shape)\n",
    "    \n",
    "    from collections import Counter\n",
    "    print('Before balancing the data')\n",
    "    print(sorted(Counter(y_train).items()))\n",
    "    from imblearn.combine import SMOTETomek\n",
    "    smote_tomek = SMOTETomek(random_state=0)\n",
    "    x_resampled, y_resampled = smote_tomek.fit_resample(x_train, y_train)\n",
    "    print('After balancing the data')\n",
    "    print('class 0 --> neutral\\n class 1 --> negative \\n class 2 --> positive')\n",
    "    print(sorted(Counter(y_resampled).items()))\n",
    "    \n",
    "    # RANDOM FOREST CLASSIFIER\n",
    "    from sklearn.pipeline import Pipeline\n",
    "    from sklearn.feature_extraction.text import TfidfTransformer\n",
    "    from sklearn.model_selection import StratifiedKFold,cross_validate,cross_val_score\n",
    "    from sklearn.metrics import classification_report\n",
    "    \n",
    "    text_clf1 = Pipeline([ ('tfidf', TfidfTransformer()),('clf', mla)])\n",
    "    print(text_clf1)\n",
    "    kfold = StratifiedKFold(n_splits=5)\n",
    "    scores = cross_val_score(text_clf1, x_resampled, y_resampled, cv=kfold, scoring='accuracy')\n",
    "    validation_score = scores.mean()\n",
    "    print('cross validation:',validation_score)\n",
    "\n",
    "    ### fit the model\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    text_clf1.fit(x_resampled,y_resampled)\n",
    "    ### prediction\n",
    "    y_pred_train = text_clf1.predict(x_resampled)\n",
    "    y_pred_test = text_clf1.predict(x_test)\n",
    "    train_score = accuracy_score(y_pred_train,y_resampled)\n",
    "    test_score = accuracy_score(y_pred_test,y_test)\n",
    "    print('train score:',train_score)\n",
    "    print('test score:',test_score)\n",
    "    print('********************************************')\n",
    "    print(' classification report:\\n',classification_report(y_pred_test,y_test,digits=3))\n",
    "\n",
    "    return validation_score,train_score,test_score\n",
    "\n",
    "        \n",
    "print('Choose brand based dataset to know about Machine Learning model')\n",
    "print('choose the below options')\n",
    "print('\\n 1.adiads Brand reviews \\n 2.skechers Brand reviews \\n 3.crocs Brand Reviews')\n",
    "try:\n",
    "    r = int(input(\"Enter number of your choice : \")) \n",
    "    \n",
    "except TypeError:\n",
    "        print(\"TypeError\")\n",
    "except:\n",
    "    print('invalid entry')\n",
    "    \n",
    "print('\\n**************************************************************************')\n",
    "print('To run the particular classifier model')\n",
    "print('choose the below options')\n",
    "print('\\n 1.Random Forest classifier \\\n",
    "        \\n 2.Decision Tree classifier \\\n",
    "        \\n 3.SGD classifier\\\n",
    "        \\n 4.Naive Bayes')\n",
    "try:\n",
    "    m = int(input(\"Enter number of your choice : \")) \n",
    "    \n",
    "except TypeError:\n",
    "        print(\"TypeError\")\n",
    "except:\n",
    "    print('invalid entry')\n",
    "switch_fun(r,m)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
